\renewcommand*\chapterpagestyle{scrheadings}
\chapter{Introduction}

This project aims to deliver a versatile voice assistant implementation
compatible with various frontends. One such frontend,
developed concurrently with this project,
leverages the Qt framework\footnote{Qt Framework \cite{qt}}
to provide a user-friendly interface.

\section{Background and Motivation}
Voice assistants have seen steady growth in adoption,
yet they are often perceived as supplementary tools
rather than essential components of productivity.
This project addresses this limitation by developing a voice assistant solution
that enhances user workflows while maintaining minimal intrusiveness.
The implementation extends traditional voice assistant capabilities
with advanced features, including workspace management and seamless speech-to-text integration.

\section{Project Scope}
The project scope encompasses the following key objectives:
\begin{itemize}
    \item Achieving efficient processing with a target response latency of 1 second.
    \item Seamless integration into Linux window managers, enabling users to control their systems using voice commands.
    \item Support for both explicit recording and voice activation functionalities.
    \item Configurability, allowing users to select preferred algorithms, APIs, and output formats.
\end{itemize}

\section{System Architecture}
\subsection{Technology Considerations}
The choice of technology stack plays a critical role in achieving low response latency.
The initial prototype of the voice assistant was developed using Kotlin and Spring Boot\footnote{Spring Framework \cite{spring}},
which provided flexibility and ease of development.
However, as the project evolved and the stringent 1-second latency goal became a priority,
it became evident that a more performant approach was necessary.

To meet this performance requirement, the project transitioned to Rust.
Rust was chosen for its ability to produce highly optimized, natively compiled binaries,
making it ideal for low-latency applications.
Additionally, Rust's emphasis on memory safety and robust error handling
ensured the reliability of the application without sacrificing speed.
Prior experience with Rust further streamlined the development process,
solidifying its selection as the optimal choice for this project.

\subsection{Design}
The voice assistant system comprises two parallel projects:
the Rust backend (the focus of this thesis) and a Qt-based frontend
(developed concurrently but outside the scope of this thesis).
The frontend serves as the user interface layer,
providing efficient access to the backend's voice processing capabilities.

The backend is designed with a modular architecture to ensure flexibility and configurability.
Each stage of the processing pipeline is responsible for a specific aspect of the voice assistant's functionality,
enabling users to choose from a variety of processing methodsâ€”whether local, remote, paid, or free.

The backend consists of the following stages:

\begin{itemize}
    \item \textbf{Recording Stage:} Implements both local and remote recording capabilities:
    \begin{itemize}
        \item Local Recorder for direct hardware access.
        \item Remote Recorder for distributed setups.
    \end{itemize}
    \item \textbf{Transcription Stage:} Provides multiple transcription options:
    \begin{itemize}
        \item Local Whisper for offline processing.
        \item Cloudflare Whisper for edge computing.
        \item OpenAI Whisper for cloud-based processing.
    \end{itemize}
    \item \textbf{Processing Stage:} Implements various natural language processing (NLP) options:
    \begin{itemize}
        \item Local NLP for offline processing.
        \item Remote NLP for distributed processing.
        \item Cloudflare NLP for edge computing.
        \item OpenAI NLP for advanced language models.
        \item Regex Matcher for simple pattern matching.
    \end{itemize}
    \item \textbf{Output Stage:} Handles the final processing results and delivers them to the user.
\end{itemize}

This modular design ensures that the voice assistant can be tailored
to meet the specific needs and preferences of its users,
offering a robust and adaptable solution for voice interaction.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/stackchart}
    \caption{System architecture illustrating the Qt frontend (parallel project)
    and the Rust backend components (the focus of this thesis).
    The processing pipeline flows from the frontend through various backend stages,
    each offering multiple implementation options.}
    \label{fig:design}
\end{figure}

\section{Integration of Artificial Intelligence in Responses}

A critical consideration in the design of the voice assistant is its handling of queries for which no specific implementation exists.
For instance, a command such as "Order a pizza" falls outside the scope of the assistant's functionality at the time of development,
though it is anticipated that such features might be supported in future iterations.
The question arises: should the assistant respond with a generic message such as "I cannot process this query,"
or should it provide a more contextually appropriate reply, such as "I am not capable of ordering food yet"?

This challenge is addressed through the integration of Large Language Models (LLMs), which are often referred to broadly as "AI" in commercial contexts.
When the assistant encounters a query that cannot be directly parsed into a predefined instruction, the query is forwarded to an LLM.
The LLM is provided with a custom prompt that contextualizes the assistant's role.
